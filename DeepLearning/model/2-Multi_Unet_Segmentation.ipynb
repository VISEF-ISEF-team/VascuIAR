{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_multi_unet_model import * # Uses softmax as last activation\n",
    "from supporters import *\n",
    "from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import imageio\n",
    "import nibabel as nib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train and mask files into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_volumetric_data():\n",
    "    train_path = '../data/MM_WHS/train_images'\n",
    "    mask_path = '../data/MM_WHS/mask_images'\n",
    "    \n",
    "    train_files = glob.glob(os.path.join(train_path, '*.nii.gz'))\n",
    "    mask_files = glob.glob(os.path.join(mask_path, '*.nii.gz'))\n",
    "\n",
    "    train_images = []\n",
    "    for index_file in range(3):\n",
    "        pat = sitk.ReadImage(train_files[index_file], sitk.sitkFloat32)\n",
    "        pat = sitk.GetArrayFromImage(pat)\n",
    "        for i in range(pat.shape[0]):\n",
    "            train_images.append(pat[i])\n",
    "            \n",
    "    mask_images = []\n",
    "    for index_file in range(3):\n",
    "        pat = sitk.ReadImage(mask_files[index_file], sitk.sitkFloat32)\n",
    "        pat = sitk.GetArrayFromImage(pat)\n",
    "        for i in range(pat.shape[0]):\n",
    "            mask_images.append(pat[i])\n",
    "        \n",
    "    train_images = np.array(train_images)\n",
    "    mask_images = np.array(mask_images)\n",
    "    return train_images, mask_images\n",
    "\n",
    "\n",
    "train_images, mask_images = read_volumetric_data()\n",
    "train_images.shape, mask_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Nifti to Folder pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .nii.gz file\n",
    "image = sitk.ReadImage(\"../data/MM_WHS/ct_train/ct_train_1001_image.nii.gz\")\n",
    "pat1001 = sitk.GetArrayFromImage(image)\n",
    "\n",
    "def convert_nii_to_image():\n",
    "    (z, x, y) = pat1001.shape \n",
    "    \n",
    "    for i in range(z): \n",
    "        img = pat1001[i,:,:]\n",
    "        img = (img - np.min(img)) / np.ptp(img)  # Normalize the data to 0 - 1\n",
    "        img = 255 * img  # Now scale by 255\n",
    "        img = img.astype(np.uint8)\n",
    "        imageio.imsave(f'../data/MM_WHS/ct_train/ct_train_1001_image/{str(i).zfill(3)}.png', img)\n",
    "        \n",
    "convert_nii_to_image()\n",
    "\n",
    "# Specify the path\n",
    "path = '../data/MM_WHS/ct_train/ct_train_1001_image'\n",
    "\n",
    "# Use glob to match the pattern '*.png', and sort the files\n",
    "files = sorted(glob.glob(os.path.join(path, '*.png')))\n",
    "\n",
    "train_images = []\n",
    "for file in files:\n",
    "    img = cv2.imread(file, 0)   \n",
    "    train_images.append(img)   \n",
    "    \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_3D_array_comparison(train_images, pat1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 pixel values -> background + 7 classes\n",
    "y_res = np.unique(mask_images)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = mask_images.shape\n",
    "mask_images_reshaped = mask_images.reshape(-1,1)\n",
    "\n",
    "mask_images_reshaped_encoded = labelencoder.fit_transform(mask_images_reshaped)\n",
    "mask_images_encoded_original_shape = mask_images_reshaped_encoded.reshape(n, h, w)\n",
    "np.unique(mask_images_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "train_images = normalize(train_images, axis=1)\n",
    "train_masks_inputs = np.expand_dims(mask_images_encoded_original_shape, axis=3)\n",
    "\n",
    "train_images.shape, train_masks_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after normalization\n",
    "np.max(train_images), np.min(train_images), np.max(train_masks_inputs), np.min(train_masks_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image after normalization\n",
    "plt.imshow(train_images[200], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "'''\n",
    "Create a subset of data for quick testing\n",
    "Picking 10% for testing and remaining for training (train set + validation set)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_inputs, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# Further split training data to a smaller subset for quick testing of models\n",
    "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(np.max(X_train), np.min(X_train), np.max(y_train), np.min(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat.shape, y_test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(mask_images_reshaped_encoded),\n",
    "                                                 mask_images_reshaped_encoded)\n",
    "print(\"Class weights are...:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet truyền thống bình thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "def get_model():\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "# can replace with focal loss\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=5, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    # class_weight=class_weights,   \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(X_train, y_train_cat, batch_size = 16, initial_epoch=5, validation_data=(X_test, y_test_cat), verbose=1, epochs=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('training/models/model_multi_v1.hdf5')\n",
    "\n",
    "# Evaluate the model\n",
    "_, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('training/models/model_multi_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('training/models/model_multi_v1.h5')\n",
    "\n",
    "_, acc = loaded_model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet kết hợp VGG. Resnet làm BackBones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# preprocess input\n",
    "x_train = preprocess_input(X_train)\n",
    "x_test = preprocess_input(X_test)\n",
    "\n",
    "# define model\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.bce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "   x=x_train,\n",
    "   y=y_train,\n",
    "   batch_size=16,\n",
    "   epochs=100,\n",
    "   validation_data=(x_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Mất mát tập huấn luyện')\n",
    "plt.plot(epochs, val_loss, 'r', label='Mất mát tập kiếm chứng')\n",
    "plt.title('Mất mát trên tập huấn luyện & kiểm chứng')\n",
    "plt.xlabel('số lần huấn luyện')\n",
    "plt.ylabel('Chỉ số mất mát')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Độ chính xác tập huấn luyện')\n",
    "plt.plot(epochs, val_acc, 'r', label='Độ chính xác tập kiểm chứng')\n",
    "plt.title('Độ chính xác trên tập huấn luyện & kiểm chứng')\n",
    "plt.xlabel('số lần huấn luyện')\n",
    "plt.ylabel('Chỉ số chính xác')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection over Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample and see what output is\n",
    "sample = sitk.ReadImage('../data/MM_WHS/train_images/ct_train_1006_image.nii.gz', sitk.sitkFloat32)\n",
    "sample = sitk.GetArrayFromImage(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.expand_dims(sample, axis=3)\n",
    "sample = normalize(sample, axis=1)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(sample)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "y_pred_argmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_pred_argmax), np.min(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res2 = np.array([ 205., 420., 500., 550., 600., 820., 850.])\n",
    "y_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.take to map the indices to values\n",
    "y_mapped = np.take(y_res2, y_pred_argmax)\n",
    "\n",
    "print(y_mapped.shape)\n",
    "np.max(y_mapped), np.min(y_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_3D_array(y_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_mapped[135], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('training/models/model_multi_v1.hdf5')  \n",
    "\n",
    "# IOU (Intersection over UNion)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "\n",
    "# Using built in keras function\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 8\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "\n",
    "# To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "\n",
    "class1_IoU = values[0,0] / (values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "class2_IoU = values[1,1] / (values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "class3_IoU = values[2,2] / (values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "class4_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "class5_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "class6_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "class7_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "class8_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)\n",
    "print(\"IoU for class3 is: \", class3_IoU)\n",
    "print(\"IoU for class4 is: \", class4_IoU)\n",
    "print(\"IoU for class4 is: \", class5_IoU)\n",
    "print(\"IoU for class4 is: \", class6_IoU)\n",
    "print(\"IoU for class4 is: \", class7_IoU)\n",
    "print(\"IoU for class4 is: \", class8_IoU)\n",
    "\n",
    "\n",
    "plt.imshow(train_images[0, :,:,0], cmap='gray')\n",
    "plt.imshow(mask_images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth = y_test[test_img_number]\n",
    "\n",
    "test_img_norm = test_img[:,:,0][:,:,None]\n",
    "test_img_input = np.expand_dims(test_img_norm, 0)\n",
    "\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n",
    "y_mapped = np.take(y_res2, predicted_img)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Tấm ảnh đầu vào')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Nhãn kiểm tra')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Kết quả dự đoán')\n",
    "plt.imshow(y_mapped, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth = y_test[test_img_number]\n",
    "\n",
    "test_img_norm = test_img[:,:,0][:,:,None]\n",
    "test_img_input = np.expand_dims(test_img_norm, 0)\n",
    "\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img = np.argmax(prediction, axis=3)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Tấm ảnh đầu vào')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Nhãn kiểm tra')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Kết quả dự đoán')\n",
    "plt.imshow(predicted_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a trained model on large image\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "large_image = cv2.imread('large_images/large_image.tif', 0)\n",
    "# This will split the image into small images of shape [3,3]\n",
    "patches = patchify(large_image, (128, 128), step=128)  # Step=256 for 256 patches means no overlap\n",
    "\n",
    "predicted_patches = []\n",
    "for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        print(i,j)\n",
    "        \n",
    "        single_patch = patches[i,j,:,:]       \n",
    "        single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n",
    "        single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
    "        single_patch_prediction = (model.predict(single_patch_input))\n",
    "        single_patch_predicted_img = np.argmax(single_patch_prediction, axis=3)[0,:,:]\n",
    "\n",
    "        predicted_patches.append(single_patch_predicted_img)\n",
    "\n",
    "predicted_patches = np.array(predicted_patches)\n",
    "predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], 128,128) )\n",
    "\n",
    "reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "plt.imshow(reconstructed_image, cmap='gray')\n",
    "plt.imsave('imgs/seg.jpg', reconstructed_image, cmap='gray')\n",
    "\n",
    "# Threshold everything above 0\n",
    "# final_prediction = (reconstructed_image > 0.01).astype(np.uint8)\n",
    "# plt.imshow(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reconstructed_image.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(221)\n",
    "plt.title('Large Image')\n",
    "plt.imshow(large_image, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.title('Prediction of large Image')\n",
    "plt.imshow(reconstructed_image, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
