{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_multi_unet_model import * # Uses softmax as last activation\n",
    "from supporters import *\n",
    "from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import imageio\n",
    "import nibabel as nib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train and mask files into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2557, 512, 512), (2557, 512, 512))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_volumetric_data():\n",
    "    train_path = '../data/MM_WHS/ct_train'\n",
    "    mask_path = '../data/MM_WHS/ct_train_mask'\n",
    "    \n",
    "    train_files = glob.glob(os.path.join(train_path, '*.nii.gz'))\n",
    "    mask_files = glob.glob(os.path.join(mask_path, '*.nii.gz'))\n",
    "\n",
    "    train_images = []\n",
    "    for index_file in range(10):\n",
    "        pat = sitk.ReadImage(train_files[index_file], sitk.sitkFloat32)\n",
    "        pat = sitk.GetArrayFromImage(pat)\n",
    "        for i in range(pat.shape[0]):\n",
    "            train_images.append(pat[i])\n",
    "            \n",
    "    mask_images = []\n",
    "    for index_file in range(10):\n",
    "        pat = sitk.ReadImage(mask_files[index_file], sitk.sitkFloat32)\n",
    "        pat = sitk.GetArrayFromImage(pat)\n",
    "        for i in range(pat.shape[0]):\n",
    "            mask_images.append(pat[i])\n",
    "        \n",
    "    train_images = np.array(train_images)\n",
    "    mask_images = np.array(mask_images)\n",
    "    return train_images, mask_images\n",
    "\n",
    "\n",
    "train_images, mask_images = read_volumetric_data()\n",
    "train_images.shape, mask_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Nifti to Folder pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .nii.gz file\n",
    "image = sitk.ReadImage(\"../data/MM_WHS/ct_train/ct_train_1001_image.nii.gz\")\n",
    "pat1001 = sitk.GetArrayFromImage(image)\n",
    "\n",
    "def convert_nii_to_image():\n",
    "    (z, x, y) = pat1001.shape \n",
    "    \n",
    "    for i in range(z): \n",
    "        img = pat1001[i,:,:]\n",
    "        img = (img - np.min(img)) / np.ptp(img)  # Normalize the data to 0 - 1\n",
    "        img = 255 * img  # Now scale by 255\n",
    "        img = img.astype(np.uint8)\n",
    "        imageio.imsave(f'../data/MM_WHS/ct_train/ct_train_1001_image/{str(i).zfill(3)}.png', img)\n",
    "        \n",
    "convert_nii_to_image()\n",
    "\n",
    "# Specify the path\n",
    "path = '../data/MM_WHS/ct_train/ct_train_1001_image'\n",
    "\n",
    "# Use glob to match the pattern '*.png', and sort the files\n",
    "files = sorted(glob.glob(os.path.join(path, '*.png')))\n",
    "\n",
    "train_images = []\n",
    "for file in files:\n",
    "    img = cv2.imread(file, 0)   \n",
    "    train_images.append(img)   \n",
    "    \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_3D_array_comparison(train_images, pat1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 205., 420., 500., 550., 600., 820., 850.], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 pixel values -> background + 7 classes\n",
    "np.unique(mask_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = mask_images.shape\n",
    "mask_images_reshaped = mask_images.reshape(-1,1)\n",
    "\n",
    "mask_images_reshaped_encoded = labelencoder.fit_transform(mask_images_reshaped)\n",
    "mask_images_encoded_original_shape = mask_images_reshaped_encoded.reshape(n, h, w)\n",
    "np.unique(mask_images_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "train_images = normalize(train_images, axis=1)\n",
    "\n",
    "train_masks_inputs = np.expand_dims(mask_images_encoded_original_shape, axis=3)\n",
    "\n",
    "# Create a subset of data for quick testing\n",
    "# Picking 10% for testing and remaining for training (train set + validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# Further split training data to a smaller subset for quick testing of models\n",
    "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_masks_reshaped_encoded),\n",
    "                                                 train_masks_reshaped_encoded)\n",
    "print(\"Class weights are...:\", class_weights)\n",
    "\n",
    "\n",
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "def get_model():\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If starting with pre-trained weights. \n",
    "# model.load_weights('???.hdf5')\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    # class_weight=class_weights,   \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('model/model_multi_v1.hdf5')\n",
    "\n",
    "# Evaluate the model\n",
    "_, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/model_multi_v1.hdf5')  \n",
    "\n",
    "# IOU (Intersection over UNion)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "\n",
    "# Using built in keras function\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "\n",
    "# To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "class1_IoU = values[0,0] / (values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "class2_IoU = values[1,1] / (values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "class3_IoU = values[2,2] / (values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "class4_IoU = values[3,3] / (values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)\n",
    "print(\"IoU for class3 is: \", class3_IoU)\n",
    "print(\"IoU for class4 is: \", class4_IoU)\n",
    "\n",
    "plt.imshow(train_images[0, :,:,0], cmap='gray')\n",
    "plt.imshow(train_masks[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a trained model on large image\n",
    "\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "large_image = cv2.imread('large_images/large_image.tif', 0)\n",
    "# This will split the image into small images of shape [3,3]\n",
    "patches = patchify(large_image, (128, 128), step=128)  # Step=256 for 256 patches means no overlap\n",
    "\n",
    "predicted_patches = []\n",
    "for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        print(i,j)\n",
    "        \n",
    "        single_patch = patches[i,j,:,:]       \n",
    "        single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n",
    "        single_patch_input=np.expand_dims(single_patch_norm, 0)\n",
    "        single_patch_prediction = (model.predict(single_patch_input))\n",
    "        single_patch_predicted_img=np.argmax(single_patch_prediction, axis=3)[0,:,:]\n",
    "\n",
    "        predicted_patches.append(single_patch_predicted_img)\n",
    "\n",
    "predicted_patches = np.array(predicted_patches)\n",
    "predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], 128,128) )\n",
    "\n",
    "reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "plt.imshow(reconstructed_image, cmap='gray')\n",
    "plt.imsave('imgs/seg.jpg', reconstructed_image, cmap='gray')\n",
    "\n",
    "plt.hist(reconstructed_image.flatten())  # Threshold everything above 0\n",
    "\n",
    "# final_prediction = (reconstructed_image > 0.01).astype(np.uint8)\n",
    "# plt.imshow(final_prediction)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(221)\n",
    "plt.title('Large Image')\n",
    "plt.imshow(large_image, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.title('Prediction of large Image')\n",
    "plt.imshow(reconstructed_image, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
